# Andr√©'s GitHub Identification Script AndreGitHubID_script-1.Rmd
====================================================================================================

## Setting things up:
Installing the required packages for R: This is to be done in the R command line and not in R studio
source("http://www.Bioconductor.org/biocLite.R") 
biocLite("BiocUpgrade")

Getting started in R: Set the working directory

Add evniroment details to allow qsub submission from within RStudio:
```{r}
Sys.setenv(SGE_ROOT="/opt/gridengine")
Sys.setenv(SGE_CELL="default")
Sys.setenv(SGE_ARCH="linux-x64")
Sys.setenv(SGE_EXECD_PORT="537")
Sys.setenv(SGE_QMASTER_PORT="536")
```

Install and load necessary packages
```{r}
install.packages("rentrez")
install.packages("xlsx")
install.packages("ape")
install.packages("seqinr")
install.packages("chemometrics")
```

Keep the library() loading separate from the install.packages chunk 
**Revise: Libraries should be loaded in the chunk their called in, except knitr**
```{r}
library(knitr)
library("xlsx")
library("ape")
library(Biostrings)
```

Generating a function to make qsub jobs and a bash script to submit them: "need to figure out a 
way to get the log files sent to the prefix folder"
```{r}
# This makes a function that generates qsub commands and a bash to submit them in parallel on 
# processors on the biocluster using 3 inputs (will be used often throughout the script whenever a
# Linux command needs to be done on several data files)

MakeQsubs <- function(cmd, prefix, suffix = ".sub", node =1) {
  dir.create(paste(sharedPathAn, prefix, sep = ""), 
             showWarnings = TRUE, 
             recursive = FALSE)
  outPath <- paste(sharedPathAn, prefix, "/", sep="")
  for(k in 1:length(cmd)) {
    cat(paste("#!/bin/bash \n",
              "#$ -S /bin/bash
              # Ensure .e and .o and other output files go to working directory
              #$ -cwd
              # Request one slot in the smp environment
              #$ -pe smp ", node, "\n",
              "# Actual linux command for qsub \n",
              cmd[k],
              sep=""),
        file=paste(outPath, prefix, k, suffix, sep="")
        )
  }
  # make a bash script to run all qsub
  cat(paste("#!/bin/bash
            #$ -S /bin/bash
            argc=$#
            requiredArgc=0
            if [ $argc -ne $requiredArgc ]; then
            echo './test_mkdir.sh'
            exit 1
            fi

            prefixInFiles=", prefix, "\n",
            "suffixInFiles=", suffix, "\n",
            "for (( i = 1; i <= ", length(cmd), " ; i++ )); do 
            # keep track of what is going on...
            echo 'Treating file'  $prefixInFiles$i$suffixInFiles
            # define a script name that will be submited to the queue
            qsubFile=$prefixInFiles$i$suffixInFiles
            # make the script executable
            chmod a+x $qsubFile
            # submit the script to the queue
            qsub -cwd $qsubFile
            done", sep=""), 
      file=paste(outPath, prefix, ".sh", sep=""))
  cat(c("\n"," *** SUBMIT FOLLOWING TWO COMMANDS FROM HEADNODE ***","\n",
        "    1- Ensure working directory given for outputs:", "\n",
        paste("cd", outPath), "\n",
        "    2- Run the bash from within this working directory:", "\n",
        paste("bash ", prefix, ".sh", sep="")))
}
# End of qsub and bash making function
```

```{r}
bashDirections <- paste("
'###############################################################################
 ##### ***** SUBMIT BASH FILE FROM HEAD NODE, AND WAIT FOR COMPLETION ****######
 #####          watch output from this command in the console             ######
 ###############################################################################'")
cat(bashDirections)
```

Function to remove output files after running qsubs:
```{r}
RemoveQsubTempFiles <- function(path, prefixSub) {
  system(paste("find ", path, prefixSub, "/", prefixSub, "*", ".sub.", "*", " -delete ", sep = ""))
}
```

## Setting up the directory structures:
Record the path to the working directory and where the fasta files are. Create a new idFolder 
directory if not already made, and manually put your query sequence(s) in the idFolder. 
```{r}
sharedPath   <- "/home/CFIA-ACIA/girouxeml/PIRL_working_directory/"
sharedPathAn <- paste(sharedPath, "output/", sep = "")
setwd(sharedPath)
idFolder  <- "Helotiales_ITS/"
dir.create(paste("", idFolder, sep = ""), 
           showWarnings = TRUE,
           recursive    = FALSE)

dir.create(paste("", idFolder, "/", "GenBank/", sep = ""), 
           showWarnings = TRUE,
           recursive    = FALSE)

genBankPath <- paste(sharedPath, idFolder, "GenBank/", sep = "")
```

## Specifying your starting query sequence(s)
### Option A: 1 starting sequence
If I want to run this script with only 1 starting sequence:
Specify Folder, read it, rename the sequence if necessary, and put that into the fasta for genBank
variable.  

1. Specify the name of the query fasta file:
```{r}
querySingleFasta <- "query.fasta"
```
&nbsp;&nbsp;&nbsp;&nbsp;2\. Provide the path to the query. Default is to place the query file in the idFolder and don't change
anything in the following chunk.
```{r}
queryPath <- paste(sharedPath, idFolder, querySingleFasta, sep = "")
```
  
OR,  

to see the fasta files in the idFolder and choose a specific one interactively:  

&nbsp;&nbsp;&nbsp;&nbsp;1. List the fasta files in the idFolder:
```{r}
idFastaFiles <- list.files(path = paste(sharedPath, idFolder, sep = ""), 
                           pattern = "\\.fas$|\\.fasta$", 
                           recursive = FALSE)
```
&nbsp;&nbsp;&nbsp;&nbsp;2\. Pick the right file(s)
```{r}
idFastaFiles
idFastaFiles <- idFastaFiles[1] # If I only want this one
idFastaFiles
querySingleFasta <- idFastaFiles
```

&nbsp;&nbsp;&nbsp;&nbsp;3\. Set the path manually:
```{r}
idFastaFiles <- paste(sharedPath, idFolder, idFastaFiles, sep = "")
queryPath    <- idFastaFiles
```


#### Read the query sequence into RStudio:
```{r}
queryFasta <- readAAStringSet(queryPath, format = "fasta")
```

*If you want to change the name of the single-query sequence, specify in the following chunk:*
```{r}
names(queryFasta) <- "Lawii_ITS1region"
```

*The query specified will be used as input to GenBank.*
```{r}
fastaForGenBank <- queryFasta
```

### Blast single query sequence to get related sequences  

#### Generate databases to blast query against:  
 
Perform sets of queries such as:
1. All of the Helotiales
2. Only the Lachnum and Lachnellula genus of Helotiales
3. Only the Lachnellula genus
4. All of the Helotiales EXCEPT the Lachnellula genus

**Prepare a csv file for your desired query searches**  
The column headers and input MUST be formatted as follows:

QueryName  | Include_organism        | Include_feature | Exclude_organism
---------- | ----------------------- | --------------- | ------------------------------------------------
Query1     | Helotiales              | rRNA            | environmental samples
Query2     | Helotiales; Sclerotinia | rRNA; misc_RNA  | environmental samples; metagenomes; unidentified

*You can have 1 or more queries and each criteria may have one or more variables. This script is not
yet adapted to blank inputs.

The following chunk reads in your prepared csv file that has your query criteria for each query 
```{r}
library("rentrez")
queryCsv      <- list.files(path = paste(sharedPath, idFolder, sep = ""), 
                            pattern = "\\.csv$", 
                            recursive = FALSE)
queryCsv
queryCsv <- queryCsv[3] # Choose the correct csv file number from those printed out in the console
queryCsv

queryMetadata <- read.csv(paste(sharedPath, idFolder, queryCsv, sep = ""), stringsAsFactors = FALSE)
queryMetadata$Include_organism <- gsub(";", "[ORGN] OR", queryMetadata$Include_organism, 
                                       ignore.case = FALSE)
queryMetadata$Include_organism <- gsub("$", "[ORGN]", queryMetadata$Include_organism, 
                                       ignore.case = FALSE)
queryMetadata$Include_feature  <- gsub(";", "[Feature] OR", queryMetadata$Include_feature, 
                                       ignore.case = FALSE)
queryMetadata$Include_feature  <- gsub("$", "[Feature]", queryMetadata$Include_feature, 
                                       ignore.case = FALSE)
queryMetadata$Exclude_organism  <- gsub(";", "[ORGN] OR", queryMetadata$Exclude_organism, 
                                       ignore.case = FALSE)
queryMetadata$Exclude_organism  <- gsub("$", "[ORGN]", queryMetadata$Exclude_organism, 
                                       ignore.case = FALSE)
queryMetadata$FullQuery <- paste("(", queryMetadata$Include_organism, 
                                 " AND (", queryMetadata$Include_feature, 
                                 ")) NOT(", queryMetadata$Exclude_organism, ")",
                                 sep = "")

write.table(queryMetadata, 
            file = file.path(paste(sharedPath, idFolder, sep = ""), "query_criteria_Full.csv"),
            append    = FALSE, 
            sep       = ",",
            quote     = FALSE,
            row.names = TRUE,
            col.names = NA)
```

#### Generate the databases as gene ID lists, *gilist.txt*, and write these to the GenBank folder:
```{r}
library("rentrez")
k <- 1
for (k in 1:nrow(queryMetadata)) {
  webEnvSearchTemp <- entrez_search(db="nuccore", queryMetadata$FullQuery[k], retmax=999999)
  cat("\n", "The length of the webEnvSearch for ", queryMetadata$QueryName[k], " is: ")
  cat(length(webEnvSearchTemp$ids))
  cat("\n")
  queryMetadata$rentrezID_length[k] <- length(webEnvSearchTemp$ids)
  queryMetadata$rentrezID_file[k]   <- paste(queryMetadata$QueryName[k], "_gilist.txt", sep = "")
  write.table(webEnvSearchTemp$ids, 
              file = paste(genBankPath, queryMetadata$QueryName[k], "_gilist.txt", sep = ""),
              append = FALSE, quote  = FALSE, row.names = FALSE, col.names = FALSE)
}

```

#### Set the Blast options and output format:  
```{r}
pathBlastn    <- "/opt/bio/ncbi-blast+/bin/blastn"
pathBlastDbNt <- "/isilon/biodiversity/reference/ncbi/blastdb/reference/nt/nt"
outfmtCols    <- c("qseqid",   "sallacc", "pident", "length", 
                   "mismatch", "gapopen", "qstart", "qend", 
                   "sstart",   "send",    "evalue", "bitscore")
maxTargetSeqs <- 400
dustBlastn    <- "no"
gapOpen       <- 1
gapExtend     <- 1
xDropGap      <- 30
xDropGapFinal <- 100
```

#### Generate the bash scripts that will perform blasts of the query against each of the query databases made.
```{r}
prefix <- "A_firstBlast"

cmd <- with(queryMetadata,
            paste(pathBlastn,
                  " -db ", pathBlastDbNt,
                  " -query ", queryPath,
                  " -max_target_seqs ", maxTargetSeqs,
                  " -gilist ", paste(genBankPath, rentrezID_file, sep = ""),
                  " -gapopen ", gapOpen,
                  " -gapextend ", gapExtend,
                  " -xdrop_gap ", xDropGap,
                  " -xdrop_gap_final ", xDropGapFinal,
                  " -dust ", dustBlastn,
                  " -outfmt '6 ", paste(outfmtCols, collapse = " "),
                  " ' -out ", paste(genBankPath, QueryName, "_GenBank.fasta.out", 
                                    sep = ""),
                  sep = ""))

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)
```

#### While the above chunk is running on the biocluster, record the name of the blast output files in the metadata table:
```{r}
for(k in 1:nrow(queryMetadata)){
    queryMetadata$BlastGB_FastaOUT <- paste(queryMetadata$QueryName, "_GenBank.fasta.out", sep = "")
}
```
*Check if the qsub job is still running:*
```{r}
system("/opt/gridengine/bin/linux-x64/qstat")
```
*Once the qsub job has finished perform the next step.*
We always want to remove temporary files that clutter the working directory, while keeping log files that audit our process and maintain a record. 
 
*Clean-up step: Remove the output files while keeping the qsub and bash file:*
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

#### Read and consolitdate BLAST outputs. I would like to fix this so that I can loop this for all the Blast output tables.
```{r}
library("seqinr")

i <- 1
newGbBlastTable <- data.frame()

for (i in 1:nrow(queryMetadata)) {
    gbBlastTable <- read.table(paste(genBankPath, queryMetadata$BlastGB_FastaOUT[i], sep = ""),
                              header = FALSE,
                              stringsAsFactors = FALSE)
    colnames(gbBlastTable) <- c("query_id",   "subject_ids", " %identity", "alignment_length",
                                "mismatches", "gap_opens",   "q_start",    " q_end",
                                "s_start",    "s_end",       "evalue",     " bit_score")
    # to break multiple gi numbers/ accessions from NCBI table
    multiGI <- cbind(gregexpr(";", gbBlastTable$subject_ids,
                              ignore.case = FALSE, 
                              perl        = FALSE, 
                              fixed       = FALSE, 
                              useBytes    = FALSE))
   # k <- 1
    for(k in 1:nrow(gbBlastTable)) { 
        if (unlist(multiGI[k])[1] != -1){ 
            parsedNames <- strsplit(as.character(gbBlastTable$subject_ids[k]), ";")[[1]]  # [[1]] to show first element 
            tempTable   <- do.call("rbind", replicate((length(unlist(multiGI[k])) + 1), 
                                                      gbBlastTable[k,], simplify = FALSE)) 
            tempTable$subject_ids <- parsedNames 
            newGbBlastTable <- rbind(newGbBlastTable, tempTable) 
            } else {
                newGbBlastTable <-  rbind(newGbBlastTable, gbBlastTable[k,]) 
                } 
        }
    gbBlastTable <- newGbBlastTable
   # Creates a +/- column for orientation of sequences
    gbBlastTable$orientation <- sign(gbBlastTable$s_end - gbBlastTable$s_start)
    gbBlastTable$length      <- abs(gbBlastTable$s_end - gbBlastTable$s_start)
    gbBlastTable$query_id    <- as.character(gbBlastTable$query_id)
    
    summary(gbBlastTable)
    colnames(gbBlastTable)[2] <- "GB_accession"
    uniqueGB <- unique(gbBlastTable$GB_accession)
    write.table(gbBlastTable,
                file = paste(genBankPath, queryMetadata$BlastGB_FastaOUT[i], ".New.txt", sep = ""),
                sep = "\t",
                append = FALSE, quote  = FALSE, row.names = FALSE, col.names = TRUE)
    write.table(uniqueGB,
                file = paste(genBankPath, queryMetadata$QueryName[i], ".uniqueGB.txt", sep = ""),
                append = FALSE, quote=FALSE, row.names=FALSE, col.names = FALSE)
}

queryMetadata$gbBlastTable     <- paste(queryMetadata$BlastGB_FastaOUT, ".New.txt", sep = "")
queryMetadata$gbBlastTablePath <- paste(genBankPath, queryMetadata$gbBlastTable, sep = "")
queryMetadata$uniqueGB         <- paste(queryMetadata$QueryName, ".uniqueGB.txt", sep = "")
queryMetadata$uniqueGBPath     <- paste(genBankPath, queryMetadata$uniqueGB, sep = "")
```



```{r}
library("ape")

i <- 1

for (i in 1:nrow(queryMetadata)) {
    uniqueGBtemp <- scan(paste(genBankPath, queryMetadata$uniqueGB[i], sep = ""), what = "", sep = "\n")
    sequences    <- read.GenBank(uniqueGBtemp,
                              seq.names = uniqueGBtemp, 
                              species.names = TRUE,
                              gene.names    = FALSE, 
                              as.character  = TRUE)
    sequenceOrder <- sequences[order(names(sequences))]
    names(sequenceOrder)[1]
    attr(sequences, "species")
    fullNames <- data.frame(attr(sequences, "species"), names(sequences), stringsAsFactors = FALSE)
    fullNames$SpStrain <-  do.call(paste, c(fullNames[1:2], sep = "_"))
    fullNamesOrdered   <- fullNames[order(fullNames$names.sequences.),] 
    nrow(fullNamesOrdered)
    
    
    # For this next loop, MUST make sure you are doing it clean and no file already exists, because
    # this loop will append as it executes.
    library(Biostrings)
    
    for(j in 1:length(sequenceOrder)) {
        gbDNAstring <- DNAStringSet()
        temp <- DNAStringSet(paste(sequenceOrder[[j]], collapse = "")) 
        names(temp)  <- fullNamesOrdered$SpStrain[j] 
        gbDNAstring  <- c(gbDNAstring, temp)
        attributes(gbDNAstring)
        writeXStringSet(gbDNAstring,
                        file = paste(genBankPath,
                                     queryMetadata$QueryName[i], ".gbDNAString.fasta", sep = ""),
                        append = TRUE, format = "fasta")
        }
    }
```

#### Add the name of the gbDNAString to the queryMetadata table: 
```{r}
queryMetadata$gbDNAString   <- paste(queryMetadata$QueryName, ".gbDNAString.fasta", sep = "")
queryMetadata$gbDNAStringPath <- paste(genBankPath, queryMetadata$gbDNAString, sep = "")
```

```{r}
i <- 3
for (i in 1:nrow(queryMetadata)) {
    gbBlastTableTemp <- read.table(queryMetadata$gbBlastTablePath[i],
                                   sep = "\t", header = TRUE, comment.char = "", quote = "",
                                   as.is = TRUE)
    gbDNAstringTemp  <- readDNAStringSet(queryMetadata$gbDNAStringPath[i])
    
    # Put together data from multiple hits on single line
    dataAggTemp <- aggregate(gbBlastTableTemp[c(2:14)],
                             by  = list(gbBlastTableTemp$GB_accession, gbBlastTableTemp$GB_accession),
                             FUN = c)
    
    # find min and max and sense of hits
    for(h in 1:nrow(dataAggTemp)) {
        dataAggTemp$min[h]   <- min(unlist(c(dataAggTemp$s_start[h],dataAggTemp$s_end[h])))
        dataAggTemp$max[h]   <- max(unlist(c(dataAggTemp$s_start[h],dataAggTemp$s_end[h])))
        dataAggTemp$sense[h] <- mean(unlist(c(dataAggTemp$orientation[h])))
        }
    
    # add a column with bp (width) of sequences.
    dataAggTemp$bp    <- width(gbDNAstring)
    dataAggTemp$width <- dataAggTemp$max - dataAggTemp$min
    dataAggTemp$diff  <- dataAggTemp$width - dataAggTemp$max
    dataAggTemp       <- dataAggTemp[order(as.character(dataAggTemp$Group.1)), ] 
    
    # to make sure that name order are the same
    checkOrderTemp <- data.frame(names(gbDNAstringTemp), dataAggTemp[,1])
    
    # Very Important
    # THE ORDER OF THESE TWO COLUMNS SHOULD BE THE SAME, SEQUENCES WILL BE OFF IF NOT
    write.table(checkOrderTemp, 
                file = paste(sharedPath, idFolder, 
                         queryMetadata$QueryName[i], "_CHECK_ORDER_OF_FASTA_AND_BLAST_TABLE.csv", 
                         sep = ""), 
                append = FALSE, 
                sep = ",", 
                col.names = NA)
    
    library("xlsx")
# http://stackoverflow.com/questions/13545547/how-to-write-a-data-frame-with-one-column-a-list-to-a-file
    dataset2Temp <- dataAggTemp # make a copy just to be on the safe side
    dataset2Temp[sapply(dataset2Temp, is.list)] <- 
        sapply(dataset2Temp[sapply(dataset2Temp, is.list)], 
               function(x)sapply(x, function(y) paste(unlist(y), collapse = ", ")))
    
    write.xlsx(dataset2Temp, 
               file = paste(sharedPath, idFolder,
                            queryMetadata$QueryName[i], "_to_check_BLAST_results_table.xlsx",
                            sep = ""),
               sheetName = "Sheet1", 
               col.names = TRUE, 
               row.names = TRUE, 
               append    = FALSE, 
               showNA    = TRUE)
    }
```

#### After running above chunk for each query, add the names of the files to the metadata table:
```{r}
queryMetadata$checkOrder <- paste(queryMetadata$QueryName, 
                                             "_CHECK_ORDER_OF_FASTA_AND_BLAST_TABLE.csv",
                                             sep = "")
queryMetadata$checkOrderPath <- paste(sharedPath, idFolder, queryMetadata$checkOrder, sep = "")
queryMetadata$dataAgg     <- paste(queryMetadata$QueryName, 
                                             "_to_check_BLAST_results_table.xlsx", sep = "")
queryMetadata$dataAggPath <- paste(sharedPath, idFolder, queryMetadata$dataAgg, sep = "")
```

#### Trim
```{r}
k <- 8 # why does Andre have this here?

gbDNAstringTemp2 <- 
xTrim <- gbDNAstring

for(k in 1:length(xTrim)) { 
    if (dataAgg$sense[k] == 1) { 
        xTrim[k] <- DNAStringSet(xTrim[k], start = dataAgg$min[k], 
                                 end = dataAgg$max[k], width = NA, use.names = TRUE) 
        print(c(k, dataAgg$sense[k])) 
        } else { 
            if (dataAgg$sense[k] == -1) {  
                xTrim[k] <- reverseComplement(DNAStringSet(xTrim[k], start = dataAgg$min[k], 
                                                           end = dataAgg$max[k], width = NA, 
                                                           use.names = TRUE)) 
                print(c(k, dataAgg$sense[k])) 
                } else { 
                    xTrim[k] <- DNAStringSet("NNNN") 
                    print(c(k, "NNNN")) 
                    } 
            } 
    }

# Show outliers
meanLength  <- mean(width(xTrim), trim = 0.05)
meanLength
queryLength <- mean(nchar(fastaForGenBank))
queryLength
```

#### Calculate a confidence interval based on all sequences

*Note: I did not finish the following chunk for query5, I lost all my sequences with the following settings for that one.*
```{r}
library("chemometrics")

confInterv <- 2*sd_trim(width(xTrim), trim=0.05, const=FALSE)

# Show the sequences that will be removed
toRemove <- xTrim[(width(xTrim) < queryLength - 1.05*confInterv | width(xTrim) > queryLength + 2*confInterv), ]
# toRemove <- xTrim[(width(xTrim) < meanLength - 10*confInterv | width(xTrim) > meanLength + 10*confInterv), ]

length(toRemove)
names(toRemove)

# Write file with removed sequences
writeXStringSet(toRemove, file = paste(sharedPath, idFolder, 
                                       metadata$queryDataBase[i], "_GB_removed.fasta", sep = ""), 
                append = FALSE, format = "fasta") 

# Create the file without the outliers
xtrimNoOutliers <- xTrim[!names(xTrim) %in% names(toRemove)]
length(xtrimNoOutliers)
names(xtrimNoOutliers)

# Write fasta file of trimmed sequences
writeXStringSet(xtrimNoOutliers, 
                file = paste(sharedPath, idFolder, 
                             metadata$queryDataBase[i], "_GB_csv_extracted.fasta", sep = ""), 
                append = FALSE, format = "fasta") 

# Concatenate the query fasta file and the fasta file of trimmed sequences to a new file:
cmd2 <- paste("cat ",  
              queryPath, " ",
              sharedPath, idFolder, metadata$queryDataBase[i], "_GB_csv_extracted.fasta > ",  
              sharedPath, idFolder, metadata$queryDataBase[i], "_to_align.fasta", 
              sep = "")
system(cmd2)
```
#### Record the name of the removed and extracted fasta files, and "to align" fasta files in the metadata table:
```{r}
for(k in 1:nrow(metadata)){
    metadata$GenGank_Removed_Fasta <- paste(metadata$queryDataBase, "_GB_removed.fasta", sep = "")
    metadata$GenGank_extracted <- paste(metadata$queryDataBase, "_GB_csv_extracted.fasta", sep = "")
    metadata$GB_to_align_fasta <- paste(metadata$queryDataBase, "_to_align.fasta", sep = "")
}
```
### Do MAFFT alignement of sequences:  
```{r}
prefix <- paste("B_alignFasta", metadata$queryDataBase[i], sep = "_")

cmd3 <- paste("/opt/bio/mafft/bin/mafft --reorder --maxiterate 1000 --localpair --thread 6 ",  
              sharedPath, idFolder, metadata$queryDataBase[i], "_to_align.fasta > ", 
              sharedPath, idFolder, metadata$queryDataBase[i], "_All_files_aligned.fasta",
              sep = "")

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd3, prefix, suffix)
```
#### Record the name of the query + blast MAFFT alignment output files in the metadata table:
```{r}
for(k in 1:nrow(metadata)){
    metadata$MAFFT_Alignment <- paste(metadata$queryDataBase, "_All_files_aligned.fasta", sep = "")
}
```
*Check if the qsub job is still running:*
```{r}
system("/opt/gridengine/bin/linux-x64/qstat")
```

*Clean-up step: Remove the output files while keeping the qsub and bash file:*
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```


```{r}
library("ape")
alignmentFile <- paste(sharedPath, idFolder, 
                       metadata$queryDataBase[i], "_All_files_aligned.fasta", sep = "")
align  <- read.dna(alignmentFile, format = "fasta")

# Raw distance is p-distance with substitution -> d: transition + transversion
dm   <- dist.dna(align, model = "raw", pairwise.deletion = TRUE, as.matrix = TRUE)
tree <- njs(dm)
maxV <- max(rowSums(dm), na.rm = TRUE)
#```

#This is to get the root of the tree with the most distant species and generate nj tree
#```{r}

myRoot <- which(rowSums(dm) == maxV)
max(dm, na.rm = TRUE)
nrow(dm)


tree <- njs(dm)
write.tree(tree, file = paste(sharedPath, idFolder, 
                              metadata$queryDataBase[i], "_nj_tree.newick", sep = ""), 
           append = FALSE, digits = 15, tree.names = FALSE)

# Code below doesn't work, because I have no root due to previous line not working.
pdf(file = paste(sharedPath, idFolder, 
                 metadata$queryDataBase[i], "_NJ_bionj_K80_tree_GenBank_and_ID_trimmed.pdf", 
                 sep = ""), 
    width = 8, height =36 )
 # "0.5-((nrow(dm)-50)/500)" is a rough equation to remove 0.1 to cex factor for every 50 taxa to keep font size small enough for larger data
  # if you want to have longer branches, reduce x.lim by 0.1 increments
  #plot.phylo(type = "phylogram", root(tree, my_root[1], node = NULL, resolve.root = TRUE), font=1, cex = 0.5,  x.lim = 0.7)
  plot.phylo(type = "phylogram", root(tree, myRoot[1], node = NULL, resolve.root = TRUE), font=1, 
      #       cex = 0.1,  x.lim = 0.07 + max(dm, na.rm = TRUE)/1.3, edge.width= 1.1 - (nrow(dm)/2000), no.margin=TRUE)
             cex = 0.54 - (sqrt(nrow(dm))/110),  x.lim = 0.07 + max(dm, na.rm = TRUE)/1.3, edge.width= 1.1 - (nrow(dm)/2000), no.margin=TRUE)
#cex = 0.54 - (sqrt(nrow(dm))/70),  x.lim = 0.07 + max(dm, na.rm = TRUE)/1.3, edge.width= 1.1 - (nrow(dm)/1200), no.margin=TRUE)
  title(main="", outer=FALSE, cex.main=1, font.main=2)
  dev.off()
```
#### Record the name of the Newick and neighbour-goining tree
in the metadata table:
```{r}
for(k in 1:nrow(metadata)){
    metadata$newick_tree <- paste(metadata$queryDataBase, "_nj_tree.newick", sep = "")
    metadata$NJ_tree     <- paste(metadata$queryDataBase, 
                                  "_NJ_bionj_K80_tree_GenBank_and_ID_trimmed.pdf", sep = "")
}
```

### Option B: >1 Starting sequences
1. Find the fasta file(s)
```{r}
idFastaFiles <- list.files(path = paste(sharedPath, idFolder, sep = ""), 
                           pattern = "\\.fas$|\\.fasta$", 
                           recursive = FALSE)
```
&nbsp;&nbsp;&nbsp;&nbsp;2\. Pick the right file(s)
```{r}
idFastaFiles
idFastaFiles <- idFastaFiles[6] # If I only want this one
idFastaFiles
```
&nbsp;&nbsp;&nbsp;&nbsp;3\. If you have more than one fasta file, put all of your files into one bigger fasta file:
```{r}
cmd <- paste(" cat ", paste(sharedPath, idFolder, as.character(idFastaFiles), 
                            collapse = " ", sep = ""),
             " > ", paste(sharedPath, idFolder, "query.fasta", sep = ""),
             sep = "")

system(cmd)

idFastaFiles <- paste(sharedPath, idFolder, "query.fasta", sep = "")
```

&nbsp;&nbsp;&nbsp;&nbsp;4\. Do a MAFFT alignment, linsi command:
```{r}

prefix    <- "A_original_query_First_MAFFT_linsi_Alignment"
linsiPath <- "/opt/bio/mafft/bin/linsi"


cmd <- paste(linsiPath, 
             " --reorder '", idFastaFiles,
             "' > ", paste(sharedPath, idFolder, "query_aligned_fasta.fasta", sep = ""),
             sep = "")

suffix <- ".sub"; cat(bashDirections); MakeQsubs(cmd, prefix, suffix)

```

*Check if the qsub job is still running:*
```{r}
system("/opt/gridengine/bin/linux-x64/qstat")
```

*Clean-up step: Remove the output files while keeping the qsub and bash file:*
```{r}
RemoveQsubTempFiles(sharedPathAn, prefix)
```

&nbsp;&nbsp;&nbsp;&nbsp;5\. Trim the alignment:
```{r}
library("ape")

align <- read.dna(paste(sharedPath, idFolder, "query_aligned_fasta.fasta", sep = ""), 
                  format = "fasta")
dm    <- dist.dna(align, model = "raw", pairwise.deletion = TRUE, as.matrix = TRUE)
tree  <- njs(dm)
maxV  <- max(rowSums(dm), na.rm = TRUE)

```

To get the root of the tree with the most distant species:
```{r}

myRoot <- which(rowSums(dm) == maxV)
max(dm, na.rm = TRUE)
nrow(dm)
pdf(file = paste(sharedPath, idFolder, "/", "NJ_tree_of_ID.pdf", sep = ""), width = 8, height = 14 )
plot.phylo(type = "phylogram", root(tree, myRoot[1], node = NULL, resolve.root = TRUE), 
           font = 1, cex = 0.52,  x.lim = 1 , edge.width = 1.1 , no.margin = TRUE)
title(main = "NJ", outer = FALSE, cex.main = 1, font.main = 2)
dev.off() 
```

Setting things up to get the number of blasts required for the tree:
```{r}
tree[[1]]
dm <- dist.dna(align, model = "raw", pairwise.deletion = FALSE, as.matrix = TRUE)
tree <- njs(dm)

pdf(file = paste(sharedPath, idFolder, "/", "NJ_tree_of_ID_for_how_many_blasts.pdf", sep = ""), 
    width = 8, height = 14 )

plot.phylo(type = "phylogram", root(tree, myRoot[1], node = NULL, resolve.root = TRUE), 
           font = 1, cex = 0.52 - (sqrt(nrow(dm))/70),  x.lim = 0.07 + max(dm, na.rm = TRUE)/1.3, 
           edge.width = 1.1 - (nrow(dm)/1200), no.margin = TRUE)

title(main = "NJ", outer = FALSE, cex.main = 1, font.main = 2)

dev.off()

dm <- dist.dna(align, model = "raw", pairwise.deletion = FALSE, as.matrix = FALSE)
fit <- hclust(dm, method = "average")

```

Number of groups based on NJ tree
```{r}

numClades <- 5 # based on the number of objects, see fit

groups <- cutree(fit, numClades)
group2 <- data.frame(names(groups), groups, stringsAsFactors = FALSE)

```

Create text file from alignment
```{r}
alignTxt <- sapply(align , function(x) toString(x))

# Remove all gaps, commas, and spaces
alignTxt <- as.character(gsub("-|,| ", "", alignTxt))
alignLength <- sapply(alignTxt , function(x) nchar(x))
group3 <- cbind(group2, alignLength, alignTxt)
group3$alignTxt <- as.character(group3$alignTxt)
```

Create a table of the different cluster with the maximum sequence length for each
```{r}
maxima <- aggregate(alignLength ~ groups, data = group3[,c(2:3)], max)

i <- 1

# Pulls out a vector with a sequence name for each maximu (pulls out the first sequence when more 
# than one have the same max length)

maximaByGroup <- vector()

for(i in 1:nrow(maxima)) {
  temp1 <- subset(group3[,c(1:3)], 
                  group3$groups == maxima$groups[i] & group3$alignLength == maxima$alignLength[i])
  temp2 <- temp1$names.groups.[!duplicated(temp1$alignLength)]
  maximaByGroup <- c(maximaByGroup, temp2)
}

sapply(group3, class)

```

Generate a fasta file that will be used to blast GenBank:
```{r}

fastaForGenBank <- group3[maximaByGroup,c(1,4)]

```

Write fasta file from the table text created to calculate length:
```{r}
library(seqinr)

write.fasta(sequences = as.list(fastaForGenBank[,2]), names = rownames(fastaForGenBank), nbchar = 80, 
            file.out  = paste(sharedPath, idFolder, "GenBank/fasta_for_GenBank.fasta", sep = ""), 
            open = "w")

fastaForGenBankPath <- paste(genBankPath, "fasta_for_GenBank.fasta", sep = "")

```


This module is to fix the GenBank output
```{r}

library("stringr")

gbNames <- names(xTrim)

# This is a loop to make some taxonomy glitches replacement to make the parsing with space accurate
   for(k in 1:length(gbNames)) {
     # This is to replace abbreviations like "R.secalis" in GenBank
       regexp1 <- " ([[:upper:]]{1})(\\.)([[:lower:]]+) "
       replacement1 <- str_extract(gbNames[k],regexp1)
       replacement1 <- sub("\\.", " ", replacement1, ignore.case = FALSE)
       gbNames[k] <- sub(" ([[:upper:]]{1})(\\.)([[:lower:]]+) ", replacement1, gbNames[k], ignore.case = FALSE)
    # This is to replace " f. sp. " for "_f._sp._"   
    #   string <- "Marssonina brunnea f. sp. multigermtubi MB_m1 tubulin beta chain (MBM_05801), mRNA"
       regexp2 <- " ([[:lower:]]+) f. sp. (\\'?)([[:lower:]]+)(\\'?) "
       replacement2 <- str_extract(gbNames[k],regexp2)
       replacement2 <- sub(" f. sp. ", "_.f._sp._", replacement2, ignore.case = FALSE)
       gbNames[k] <- sub(" ([[:lower:]]+) f. sp. (\\'?)([[:lower:]]+)(\\'?) ", replacement2, gbNames[k], ignore.case = FALSE)
   }
  

gbNames <- sub(" ", "|", gbNames, ignore.case = FALSE)
gbNames <- sub(" ", "|", gbNames, ignore.case = FALSE)
gbNames <- sub(" ", "|", gbNames, ignore.case = FALSE)


# *** Over here!!! This doesn't work...
parsedCol <- data.frame(matrix(unlist(strsplit(as.character(gbNames), "\\|")), 
                               nrow  = length(gbNames), 
                               byrow = T),
                        stringsAsFactors = FALSE)


# This is a loop to make extract strain numbers.  There are two approaches, one when there is "strain|isolate|voucher" and one 
# where the strain number is right after species of f.sp. name.  This may need to be tweaked for different strain codes
  for(i in 1:length(parsedCol$X8)) {
      if  (grepl("strain|isolate|voucher", parsedCol$X8[i])) {   
        regexp <- "(strain|isolate|voucher) ([[:alpha:]]*)( ?|\\-*|\\_*)([[:digit:]]*|[[:upper:]]*)(\\.*|\\-*)([[:digit:]]*|[[:upper:]]*)"
        parsedCol$strain[i] <- str_extract(parsedCol$X8[i],regexp)
      } else {
        # the trick for this was to leave a blank when there is no strain number
        regexp <- "([[:upper:]]*)( ?|\\-*|\\_*)([[:digit:]]*|[[:upper:]]*)(\\.*|\\-*)([[:digit:]]*|([[:alpha:]]+[[:digit:]]+))"
        parsedCol$strain[i] <- str_extract(parsedCol$X8[i],regexp) } 
    }

# remove strain|isolate|voucher in strain codes
parsedCol$strain2 <- sub("strain |isolate |voucher ", "", parsedCol$strain, ignore.case = FALSE)
parsedCol$strain2 <- sub("_", "", parsedCol$strain2, ignore.case = FALSE)
parsedCol$strain2 <- sub(" ", "", parsedCol$strain2, ignore.case = FALSE)
parsedCol$GB <- sub("\\.[[:digit:]]", "", parsedCol$X4, ignore.case = FALSE)
parsedCol$GB <- sub("_", "", parsedCol$GB, ignore.case = FALSE)
parsedCol$species <- gsub("_", "", parsedCol$X7, ignore.case = FALSE)
#for_names <- paste(parsedCol$X6,"_",parsedCol$species,"_",parsedCol$GB,"_strain(",parsedCol$strain2,")", sep = "")
names(x_trim) <- paste(parsedCol$X6,"_",parsedCol$species,"_",parsedCol$GB,"_strain(",parsedCol$strain2,")", sep = "")

writeXStringSet(x_trim, file="new_names.fasta", append=FALSE, format="fasta") 
```

**** Over here!!! Need to fix, removed loop I was trying to make in the previous chunk, so 
now must reset the arrangement for the chunk below:
```{r}
#i <- 6   # This is for our query1 database for BLAST 

gbBlastTable <- read.table(paste(genBankPath, queryMetadata$BlastGB_FastaOUT[i], sep = ""),
                           header = FALSE,
                           stringsAsFactors = FALSE)

colnames(gbBlastTable) <- c("query_id",   "subject_ids", " %identity", "alignment_length", 
                            "mismatches", "gap_opens",   "q_start",    " q_end", 
                            "s_start",    "s_end",       "evalue",     " bit_score")
# to break multiple gi numbers/ accessions from NCBI table
multiGI <- cbind(gregexpr(";", gbBlastTable$subject_ids,
                          ignore.case = FALSE, 
                          perl        = FALSE, 
                          fixed       = FALSE, 
                          useBytes    = FALSE))

newGbBlastTable <- data.frame()
for(k in 1:nrow(gbBlastTable)) { 
    if (unlist(multiGI[k])[1] != -1){ 
        parsedNames <- strsplit(as.character(gbBlastTable$subject_ids[k]), ";")[[1]]  # [[1]] to show first element 
        tempTable   <- do.call("rbind", replicate((length(unlist(multiGI[k])) + 1), 
                                                   gbBlastTable[k,], simplify = FALSE)) 
        tempTable$subject_ids <- parsedNames 
        newGbBlastTable <- rbind(newGbBlastTable, tempTable) 
        } else {
            newGbBlastTable <-  rbind(newGbBlastTable, gbBlastTable[k,]) 
            } 
    }

gbBlastTable <- newGbBlastTable 
summary(gbBlastTable)
colnames(gbBlastTable)[2] <- "GB_accession"
uniqueGB <- unique(gbBlastTable$GB_accession)
```


```{r}
library("ape")
sequences <- read.GenBank(uniqueGB, 
                          seq.names = uniqueGB, 
                          species.names = TRUE,
                          gene.names    = FALSE, 
                          as.character  = TRUE)

sequenceOrder <- sequences[order(names(sequences))]
names(sequenceOrder)[1]
attr(sequences, "species")

fullNames <- data.frame(attr(sequences, "species"), names(sequences), stringsAsFactors = FALSE)
fullNames$SpStrain <-  do.call(paste, c(fullNames[1:2], sep = "_"))
fullNamesOrdered   <- fullNames[order(fullNames$names.sequences.),] 
nrow(fullNamesOrdered)
```

```{r}
library(Biostrings)

gbDNAstring <- DNAStringSet()

for(k in 1:length(sequenceOrder)) { 
    temp <- DNAStringSet(paste(sequenceOrder[[k]], collapse = "")) 
    names(temp)  <- fullNamesOrdered$SpStrain[k] 
    gbDNAstring  <- c(gbDNAstring, temp)
} 

# Creates a +/- column for orientation of sequences
gbBlastTable$orientation <- sign(gbBlastTable$s_end - gbBlastTable$s_start)
gbBlastTable$length      <- abs(gbBlastTable$s_end - gbBlastTable$s_start)
gbBlastTable$query_id    <- as.character(gbBlastTable$query_id)

# Put together data from multiple hits on single line
dataAgg <- aggregate(gbBlastTable[c(2:14)], 
                     by  = list(gbBlastTable$GB_accession, gbBlastTable$GB_accession),
                     FUN = c)

# find min and max and sense of hits
for(k in 1:nrow(dataAgg)) {
  dataAgg$min[k]   <- min(unlist(c(dataAgg$s_start[k],dataAgg$s_end[k])))
  dataAgg$max[k]   <- max(unlist(c(dataAgg$s_start[k],dataAgg$s_end[k])))
  dataAgg$sense[k] <- mean(unlist(c(dataAgg$orientation[k]))) 
}


# add a column with bp (width) of sequences.
dataAgg$bp    <- width(gbDNAstring)
dataAgg$width <- dataAgg$max - dataAgg$min
dataAgg$diff  <- dataAgg$width - dataAgg$max
dataAgg       <- dataAgg[order(as.character(dataAgg$Group.1)), ] 

# to make sure that name order are the same
checkOrder <- data.frame(names(gbDNAstring), dataAgg[,1])

# Very Important
# THE ORDER OF THESE TWO COLUMNS SHOULD BE THE SAME
# SEQUENCES WILL BE OFF IF NOT
write.table(checkOrder, 
            file = paste(sharedPath, idFolder, 
                         metadata$queryDataBase[i], "_CHECK_ORDER_OF_FASTA_file_AND_BLAST_TABLE.csv", 
                         sep = ""), 
            append = FALSE, 
            sep = ",", 
            col.names = NA)
```



